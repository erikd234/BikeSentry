{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc5bd74a",
   "metadata": {},
   "source": [
    "# Because virtualenvs and python interpreters are being incredibly annoying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d07bc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.19.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamf\\AppData\\Local\\Temp/ipykernel_27188/950084747.py:57: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  arr = np.array([freq.astype(int), Y.astype(int)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99998564]]\n",
      "[[0.99964786]]\n"
     ]
    }
   ],
   "source": [
    "# Author: Adam Fong\n",
    "# Date: December 27, 2021\n",
    "# Purpose: Create a function that takes a wave file and preprocesses it to be valid input for angle grinder tflite model\n",
    "\n",
    "## TODO: Impove processing time by a lot. Currently takes 9s to process a 2 second clip (well I guess 2, 2 second clips)\n",
    "\n",
    "# NOTE: to run tflite_runtime.interpreter you need numpy ~1.19.2\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pickle import load\n",
    "import scipy.io.wavfile as wav\n",
    "import tensorflow as tf\n",
    "\n",
    "print(np.__version__)\n",
    "samplerate = 44100\n",
    "N_BINS = 1000\n",
    "\n",
    "# making chunk size\n",
    "# currently only neat if each chunk is 1 second \n",
    "def createChunks(raw_data_array):\n",
    "    seconds = 2\n",
    "    chunk_size = int(seconds * samplerate)\n",
    "    chunks_final = pd.DataFrame([np.zeros(chunk_size)])\n",
    "\n",
    "    # if seconds != 1, there will be some lost data. Hard to avoid this if we are going to have a lot of time recorded \n",
    "    # removes time from the beginning of the recording because there is more often noise there than at the end\n",
    "    for rec in raw_data_array:\n",
    "        n_chunks = math.floor(len(rec) / chunk_size)\n",
    "        for i in range(len(rec) - (n_chunks * chunk_size), len(rec), chunk_size):\n",
    "            chunk = rec[i:(i+chunk_size)]\n",
    "            #print(f\"Length: {len(chunk)}, First Value: {chunk[0]}, Last Value: {chunk[len(chunk) - 1]}\")\n",
    "            chunks_final = chunks_final.append(pd.Series(chunk), ignore_index = True)\n",
    "\n",
    "    # get rid of filler zero's line\n",
    "    chunks_final = chunks_final.iloc[1:, :]\n",
    "    return chunks_final\n",
    "\n",
    "def rawAudioToFreq(arr: np.array, bins: int):\n",
    "    n = len(arr)                       # length of the signal\n",
    "    k = np.arange(n)\n",
    "    T = n/samplerate\n",
    "    \n",
    "    frq = k/T # two sides frequency range\n",
    "    \n",
    "    \n",
    "    zz=int(n/2)\n",
    "    freq = frq[range(zz)]           # one side frequency range\n",
    "    Y0 = np.fft.fft(arr)/n              # fft computing and normalization\n",
    "    Y = Y0[range(zz)]\n",
    "\n",
    "    # obtaining maximum amplitude and its corresponding frequency \n",
    "    Y_max = abs(Y).max()\n",
    "    freq_max = freq[np.where(abs(Y) == Y_max)[0][0]]\n",
    "    \n",
    "    arr = np.array([freq.astype(int), Y.astype(int)])\n",
    "    bin_size = math.floor(arr[0, arr.shape[1]-1] / bins)\n",
    "    bin_minimums = np.arange(0, arr[0, arr.shape[1] - 1], bin_size)\n",
    "    bin_arr = np.array([bin_minimums, np.zeros(len(bin_minimums))])\n",
    "\n",
    "    # collecting magintudes in bins \n",
    "    for i in range(0, arr[0, arr.shape[1] - 1], math.floor(bin_size)):\n",
    "        bin_arr[1, int(i / bin_size)] = np.sum(abs(Y)[i:(i+bin_size)])\n",
    "\n",
    "    return freq, abs(Y), bin_arr, Y_max, freq_max\n",
    "\n",
    "def getFreqs(chunk_df: pd.DataFrame, bins: int):\n",
    "    freqs, Ys, bin_array, Y_max, freq_max = rawAudioToFreq(chunk_df.to_numpy()[0, :], bins)\n",
    "#     for row in range(chunk_df.shape[0]):\n",
    "        \n",
    "#         freqs, Ys, bin_array, Y_max, freq_max = rawAudioToFreq(chunk_df.to_numpy()[row, :], bins)\n",
    "\n",
    "#         # don't want the bin array if there's only one sample to check\n",
    "#         if row == 0:\n",
    "#             freqs_df = pd.DataFrame([bin_array[0, :]])\n",
    "#         else:\n",
    "#         freqs_df = freqs_df.append(pd.Series(bin_array[1,:]), ignore_index = True)\n",
    "    return pd.DataFrame([pd.Series(bin_array[1,:])])\n",
    "\n",
    "def audioProcessor(file):\n",
    "    # loading the same scaler that scaled the data for model training \n",
    "    scaler = load(open('C:/Users/adamf/OneDrive/Documents/university/UBC/homework_Winter_2021/IGEN_330/BikeSentry/device/audio_recognition/fft_examples/audio_scaler.pkl', 'rb'))\n",
    "\n",
    "    # take file and convert to pandas dataframe\n",
    "    sr, y = wav.read(file)\n",
    "    \n",
    "    # time of clips\n",
    "    s = 2 #seconds\n",
    "\n",
    "    if y.shape[1] == 2: # for 2 channel audio recording (iPhone)\n",
    "        y0 = y[:(sr*s), 0]\n",
    "        y1 = y[:(sr*s), 1]\n",
    "        \n",
    "        chunk0 = pd.DataFrame([y0])\n",
    "        chunk1 = pd.DataFrame([y1])\n",
    "        \n",
    "        freqs0 = getFreqs(chunk0, N_BINS)\n",
    "        freqs1 = getFreqs(chunk1, N_BINS)\n",
    "        \n",
    "        freqs_scaled0 = scaler.fit_transform(freqs0.to_numpy()[0,:].reshape(-1,1))\n",
    "        freqs_scaled1 = scaler.fit_transform(freqs1.to_numpy()[0,:].reshape(-1,1))\n",
    "\n",
    "        return(2, [freqs_scaled0, freqs_scaled1])\n",
    "    else: # 1 channel audio recording (our mic)\n",
    "        # force file to exactly 2 seconds or 44.1k * 2sec samples\n",
    "        y = y[:sr*s]\n",
    "\n",
    "        # create chunk\n",
    "        chunk = createChunks([y])\n",
    "\n",
    "        # get frequencies\n",
    "        freqs = getFreqs(chunk, N_BINS)\n",
    "\n",
    "        # scale frequencies\n",
    "        freqs_scaled = scaler.fit_transform(freqs.to_numpy()[0, :].reshape(-1,1)) #first row is bin values\n",
    "\n",
    "        return (1, freqs_scaled)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # load ML model\n",
    "    interpreter = tf.lite.Interpreter(model_path = \"angle-grinder-detector-2s.tflite\")\n",
    "    interpreter.allocate_tensors()\n",
    "    \n",
    "    # get data from file\n",
    "    filename = \"C:/Users/adamf/OneDrive/Documents/university/UBC/homework_Winter_2021/IGEN_330/BikeSentry_data/angle-grinders/red-4m-trimmed.wav\"\n",
    "    _, test = wav.read(filename)\n",
    "    \n",
    "    # Get input and output tensors.\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    # process data\n",
    "    channels, inp = audioProcessor(filename)\n",
    "    \n",
    "    # change to float32\n",
    "    inp = np.float32(inp)\n",
    "        \n",
    "    # Test the model on random input data.\n",
    "    input_shape = input_details[0]['shape']\n",
    "    \n",
    "    #set value of input tensor\n",
    "    if channels == 1: # one channel audio\n",
    "        input_data = inp\n",
    "        \n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "        interpreter.invoke()\n",
    "        \n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "        print(output_data)\n",
    "    else: # more than 1 channel audio\n",
    "        for channel in range(channels):\n",
    "            input_data = inp[channel].T\n",
    "            interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "            interpreter.invoke()\n",
    "\n",
    "            output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "            \n",
    "            print(output_data)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bikesentry",
   "language": "python",
   "name": "bikesentry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
